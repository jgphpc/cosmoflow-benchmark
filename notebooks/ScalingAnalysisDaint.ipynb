{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosmoFlow Benchmark Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(result_dir):\n",
    "    config_file = os.path.join(result_dir, 'config.pkl')\n",
    "    with open(config_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_result(result_dir):\n",
    "    history_file = os.path.join(result_dir, 'history.csv')\n",
    "    return pd.read_csv(history_file)\n",
    "\n",
    "def compute_mean_time(r):\n",
    "    return r[r.epoch>0].time.mean()\n",
    "\n",
    "def get_num_samples(config, ranks):\n",
    "    dconf = config['data']\n",
    "    n = dconf['n_train'] + dconf['n_valid']\n",
    "    if not dconf['shard']:\n",
    "        n *= ranks\n",
    "    return n\n",
    "\n",
    "def get_scaling_results(path_pattern, ranks):\n",
    "    \"\"\"\n",
    "    Loops over ranks with specified file path pattern and computes scaling metrics.\n",
    "    Returns results in a dataframe.\n",
    "    \"\"\"\n",
    "    configs, results = [], []\n",
    "    for r in ranks:\n",
    "        result_dir = path_pattern % r\n",
    "        configs.append(load_config(result_dir))\n",
    "        results.append(load_result(result_dir).assign(ranks=r))\n",
    "    samples = np.array([get_num_samples(c,r) for (c,r) in zip(configs, ranks)])    \n",
    "    times = np.array([compute_mean_time(r) for r in results])\n",
    "    throughputs = samples / times\n",
    "    ideal = ranks * throughputs[0]\n",
    "    eff = throughputs / ideal\n",
    "    return pd.DataFrame(dict(ranks=ranks, samples=samples,\n",
    "                             times=times, throughputs=throughputs,\n",
    "                             ideal=ideal, eff=eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MLPERF_HPC_ROOT=/home/lukasd/src/mlperf\n",
    "\n",
    "#%env MLPERF_COSMO_GPU_TIMESTAMP=weak_scaling/2020-08-03_12-43-00_daint101\n",
    "\n",
    "# New measurement\n",
    "%env MLPERF_COSMO_GPU_TIMESTAMP=weak_scaling/2020-08-06_16-34-59_daint101\n",
    "\n",
    "\n",
    "%env MLPERF_COSMO_CPU_TIMESTAMP=weak_scaling/2020-08-03_15-15-51_daint101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"## GPU experiments ##\"\n",
    "ls -l ${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_GPU_TIMESTAMP}\n",
    "echo \"\"\n",
    "echo \"## CPU experiments ##\"\n",
    "ls -l ${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_CPU_TIMESTAMP}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daint GPU scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_gpu = get_scaling_results(\n",
    "    os.path.expandvars('${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_GPU_TIMESTAMP}/scaling-gpu-n%i'),\n",
    "    ranks=np.array([1, 2, 4, 8, 16, 32, 64]))\n",
    "\n",
    "results_gpu_dummy = get_scaling_results(\n",
    "    os.path.expandvars('${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_GPU_TIMESTAMP}/scaling-gpu-dummy-n%i'),\n",
    "    ranks=np.array([1, 2, 4, 8, 16, 32, 64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Summary table\n",
    "results_gpu.merge(results_gpu_dummy, on='ranks', suffixes=(None,'_dummy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(8,8),\n",
    "                               gridspec_kw=dict(height_ratios=[.8, .2], hspace=0))\n",
    "\n",
    "ax0.set_title('Daint GPU scaling')\n",
    "ax0.plot(results_gpu.ranks, results_gpu.throughputs, 'o-', ms=8, label='Real data')\n",
    "ax0.plot(results_gpu_dummy.ranks, results_gpu_dummy.throughputs, '^-', ms=8, label='Dummy data')\n",
    "ax0.plot(results_gpu.ranks, results_gpu.ideal, '--', label='Ideal')\n",
    "ax0.set_ylabel('Training throughput [samples/s]')\n",
    "ax0.set_yscale('log')\n",
    "ax0.legend(loc=0)\n",
    "ax0.grid()\n",
    "\n",
    "# Scaling efficiency\n",
    "ax1.plot(results_gpu.ranks, results_gpu.eff, 'o-', ms=8)\n",
    "#ax1.plot(results_gpu_dummy.ranks, results_gpu.eff, '^-', ms=8)\n",
    "ax1.set_xlabel('Number of workers')\n",
    "ax1.set_ylabel('Efficiency')\n",
    "ax1.set_ylim(bottom=0.75)\n",
    "ax1.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(results.ranks)\n",
    "ax1.xaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "ax1.grid()\n",
    "\n",
    "# Customize y-axis\n",
    "throughput_ticks = np.array([(1.*scale, 3.*scale) for scale in np.logspace(1,3,3)]).flatten()[1:-1] #[100, 300, 1000, 3000, 10000, 30000, 100000]\n",
    "ax0.set_yticks(throughput_ticks)\n",
    "ax0.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "ax1.set_yticks(np.linspace(0.75, 1., 6))\n",
    "ax1.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daint CPU scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = get_scaling_results(\n",
    "    os.path.expandvars('${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_CPU_TIMESTAMP}/scaling-cpu-n%i'),\n",
    "    ranks=np.array([1, 2, 4, 8, 16, 32, 64]))\n",
    "\n",
    "results_dummy = get_scaling_results(\n",
    "    os.path.expandvars('${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_CPU_TIMESTAMP}/scaling-cpu-dummy-n%i'),\n",
    "    ranks=np.array([1, 2, 4, 8, 16, 32, 64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "path_pattern = os.path.expandvars('${MLPERF_HPC_ROOT}/cosmoflow-benchmark/results/${MLPERF_COSMO_CPU_TIMESTAMP}/scaling-cpu-dummy-n%i')\n",
    "ranks=np.array([1, 2, 4]) #, 8, 16, 32, 64])\n",
    "\n",
    "\n",
    "def compute_mean_time(r):\n",
    "    return r[r.epoch>0].time.mean()\n",
    "\n",
    "configs, results = [], []\n",
    "for r in ranks:\n",
    "    result_dir = path_pattern % r\n",
    "    configs.append(load_config(result_dir))\n",
    "    results.append(load_result(result_dir).assign(ranks=r))\n",
    "samples = np.array([get_num_samples(c,r) for (c,r) in zip(configs, ranks)])    \n",
    "times = np.array([r.time.mean() for r in results])\n",
    "throughputs = samples / times\n",
    "ideal = ranks * throughputs[0]\n",
    "eff = throughputs / ideal\n",
    "pd.DataFrame(dict(ranks=ranks, samples=samples,\n",
    "                  times=times, throughputs=throughputs,\n",
    "                  ideal=ideal, eff=eff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "dconf = configs[0]['data']\n",
    "n = dconf['n_train'] + dconf['n_valid']\n",
    "if not dconf['shard']:\n",
    "    n *= ranks\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Summary table\n",
    "results.merge(results_dummy, on='ranks', suffixes=(None,'_dummy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(8,8),\n",
    "                               gridspec_kw=dict(height_ratios=[.8, .2], hspace=0))\n",
    "\n",
    "ax0.set_title('Daint CPU scaling')\n",
    "ax0.plot(results.ranks, results.throughputs, 'o-', ms=8, label='Real data')\n",
    "ax0.plot(results_dummy.ranks, results_dummy.throughputs, '^-', ms=8, label='Dummy data')\n",
    "ax0.plot(results.ranks, results.ideal, '--', label='Ideal')\n",
    "ax0.set_ylabel('Training throughput [samples/s]')\n",
    "ax0.set_yscale('log')\n",
    "ax0.legend(loc=0)\n",
    "ax0.grid()\n",
    "\n",
    "# Scaling efficiency\n",
    "ax1.plot(results.ranks, results.eff, 'o-', ms=8)\n",
    "ax1.set_xlabel('Number of workers')\n",
    "ax1.set_ylabel('Efficiency')\n",
    "ax1.set_ylim(bottom=0.5)\n",
    "ax1.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(results.ranks)\n",
    "ax1.xaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "ax1.grid()\n",
    "\n",
    "# Customize y-axis\n",
    "throughput_ticks = np.array([(1.*scale, 3.*scale) for scale in np.logspace(-1,1,3)]).flatten()[1:] #[100, 300, 1000, 3000, 10000, 30000, 100000]\n",
    "ax0.set_yticks(throughput_ticks)\n",
    "ax0.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "ax1.set_yticks(np.linspace(0.5, 1., 6))\n",
    "ax1.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
